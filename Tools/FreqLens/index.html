<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FreqLens - Audio Analyzer</title>
    <!-- Tailwind CSS CDN for modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for overall responsiveness and appearance */
        body {
            font-family: 'Inter', sans-serif; /* Using Inter font as per instructions */
            background-color: #f0f4f8; /* Light background color */
            color: #333; /* Default text color */
            min-height: 100vh; /* Full viewport height */
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px; /* Padding around the content */
        }
        .container {
            max-width: 900px; /* Max width for the main content container */
            width: 100%; /* Full width on smaller screens */
            background-color: #fff; /* White background for the container */
            padding: 30px; /* Inner padding */
            border-radius: 12px; /* Rounded corners for the container */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1); /* Soft shadow */
            margin-bottom: 20px; /* Space at the bottom */
        }
        canvas {
            display: block;
            background-color: #e2e8f0; /* Light gray background for canvas */
            border-radius: 8px; /* Rounded corners for canvases */
            margin-top: 20px;
            width: 100%; /* Make canvas responsive to its parent width */
            height: auto; /* Maintain aspect ratio (though height is fixed by JS) */
            box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.06); /* Inner shadow for depth */
        }
        .detail-item {
            padding: 8px 0;
            border-bottom: 1px dashed #cbd5e1; /* Dashed separator for details */
        }
        .detail-item:last-child {
            border-bottom: none; /* No border for the last item */
        }
        /* Styling for the loading spinner */
        .loading-spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db; /* Blue top border */
            border-radius: 50%; /* Circular shape */
            width: 30px;
            height: 30px;
            animation: spin 1s linear infinite; /* Spin animation */
            display: none; /* Hidden by default */
            margin: 20px auto; /* Centered margin */
        }
        /* Keyframe animation for the spinner */
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        /* Utility class to hide elements */
        .hidden {
            display: none;
        }

        /* Message box overlay styles */
        #messageBox {
            z-index: 1000; /* Ensure it's on top */
        }
        /* Style for progress bar */
        #audioProgressBar {
            -webkit-appearance: none;
            appearance: none;
            width: 100%;
            height: 8px;
            background: #d1d5db; /* gray-300 */
            border-radius: 4px;
            outline: none;
            cursor: pointer;
            overflow: hidden; /* This is crucial for the filled background */
        }

        #audioProgressBar::-webkit-progress-bar {
            background-color: #d1d5db; /* gray-300 */
            border-radius: 4px;
        }

        #audioProgressBar::-webkit-progress-value {
            background-color: #4f46e5; /* indigo-600 */
            border-radius: 4px;
        }

        #audioProgressBar::-moz-progress-bar {
            background-color: #4f46e5; /* indigo-600 */
            border-radius: 4px;
        }

        /* Style for volume slider */
        #volumeSlider {
            -webkit-appearance: none;
            appearance: none;
            width: 100%;
            height: 8px;
            background: #d1d5db; /* gray-300 */
            border-radius: 4px;
            outline: none;
            cursor: pointer;
        }

        #volumeSlider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 18px;
            height: 18px;
            background: #4f46e5; /* indigo-600 */
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 0 2px rgba(0, 0, 0, 0.3);
            margin-top: -5px; /* Adjust thumb vertical position */
        }

        #volumeSlider::-moz-range-thumb {
            width: 18px;
            height: 18px;
            background: #4f46e5; /* indigo-600 */
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 0 2px rgba(0, 0, 0, 0.3);
        }
    </style>
</head>
<body class="selection:bg-blue-200 selection:text-blue-800">
    <div class="container">
        <h1 class="text-4xl font-extrabold text-center mb-6 text-gray-800">FreqLens - Audio Analyzer By Abdur Rahman</h1>
        <p class="text-center text-gray-600 mb-8">Upload an audio file to view its detailed properties, frequency spectrum, and waveform.</p>
        <!-- Audio file input section -->
        <div class="flex flex-col items-center mb-8">
            <label for="audioFile" class="bg-gradient-to-r from-blue-500 to-indigo-600 text-white font-semibold py-3 px-8 rounded-full shadow-lg hover:shadow-xl transform hover:-translate-y-1 transition-all duration-300 cursor-pointer">
                Choose Audio File
            </label>
            <input type="file" id="audioFile" accept="audio/*" class="hidden" />
            <span id="fileNameDisplay" class="mt-4 text-gray-700 font-medium">No file selected</span>
        </div>

        <!-- Loading spinner -->
        <div id="loadingIndicator" class="loading-spinner"></div>

        <!-- File details display section -->
        <div id="file-details" class="bg-gray-50 p-6 rounded-lg shadow-inner mb-8 hidden">
            <h2 class="text-2xl font-semibold text-gray-700 mb-4 border-b-2 border-blue-400 pb-2">File Details</h2>
            <!-- Audio details will be dynamically injected here by JavaScript -->
        </div>

        <!-- Audio playback controls -->
        <div id="audioControls" class="flex flex-col items-center gap-4 mb-8 hidden">
            <div class="flex justify-center gap-4 w-full">
                <button id="playButton" class="bg-green-500 hover:bg-green-600 text-white font-bold py-3 px-6 rounded-lg shadow-md transition duration-300 flex items-center gap-2">
                    <!-- Play icon (SVG) -->
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clip-rule="evenodd" />
                    </svg>
                    Play
                </button>
                <button id="pauseButton" class="bg-red-500 hover:bg-red-600 text-white font-bold py-3 px-6 rounded-lg shadow-md transition duration-300 flex items-center gap-2">
                    <!-- Pause icon (SVG) -->
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clip-rule="evenodd" />
                    </svg>
                    Pause
                </button>
            </div>

            <!-- Volume Control -->
            <div class="w-full max-w-sm flex items-center gap-3">
                <span class="text-gray-700 font-semibold">Volume:</span>
                <input type="range" id="volumeSlider" min="0" max="1" step="0.01" value="1" class="flex-grow">
            </div>

            <!-- Audio Progress Bar -->
            <div class="w-full flex items-center gap-2 text-sm font-medium text-gray-700">
                <span id="currentTimeDisplay">00:00</span>
                <input type="range" id="audioProgressBar" min="0" max="0" value="0" class="flex-grow h-2 rounded-md appearance-none cursor-pointer bg-gray-300 [&::-webkit-slider-thumb]:w-3 [&::-webkit-slider-thumb]:h-3 [&::-webkit-slider-thumb]:rounded-full [&::-webkit-slider-thumb]:bg-indigo-600 [&::-webkit-slider-thumb]:shadow [&::-webkit-slider-runnable-track]:bg-gray-300 [&::-webkit-slider-runnable-track]:rounded-md" />
                <span id="durationDisplay">00:00</span>
            </div>
        </div>

        <!-- Real-time audio metrics -->
        <div id="realtimeMetrics" class="bg-gray-50 p-4 rounded-lg shadow-inner mb-8 hidden">
            <h2 class="text-xl font-semibold text-gray-700 mb-3 border-b border-gray-300 pb-2">Real-time Metrics</h2>
            <div class="flex justify-around text-lg">
                <div class="text-center">
                    <span class="font-bold text-blue-700">Dominant Freq:</span> <span id="currentDominantFrequency">0.00</span> Hz
                </div>
                <div class="text-center">
                    <span class="font-bold text-purple-700">Peak Amplitude:</span> <span id="currentPeakAmplitude">0.00</span> (0-1)
                </div>
            </div>
        </div>

        <!-- Frequency spectrum visualization canvas -->
        <h2 class="text-2xl font-semibold text-gray-700 mb-4 border-b-2 border-blue-400 pb-2 hidden" id="frequencyTitle">Frequency Spectrum</h2>
        <canvas id="frequencyCanvas"></canvas>

        <!-- Waveform visualization canvas -->
        <h2 class="text-2xl font-semibold text-gray-700 mb-4 border-b-2 border-blue-400 pb-2 hidden" id="waveformTitle">Waveform</h2>
        <canvas id="waveformCanvas"></canvas>

        <!-- Custom Message Box Modal (hidden by default) -->
        <div id="messageBox" class="fixed inset-0 bg-gray-600 bg-opacity-50 flex items-center justify-center hidden">
            <div class="bg-white p-6 rounded-lg shadow-xl max-w-sm w-full text-center">
                <p id="messageBoxText" class="text-lg text-gray-800 mb-4"></p>
                <button id="messageBoxClose" class="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded-lg">OK</button>
            </div>
        </div>
    </div>

    <script>
        // Global variables for Web Audio API components
        let audioContext;
        let analyser;
        let audioElement;
        let sourceNode; // MediaElementSourceNode connected to the analyser
        let audioBuffer; // Stores the decoded audio buffer for metadata access

        // Canvas elements and their 2D rendering contexts
        let frequencyCanvas, waveformCanvas;
        let frequencyCanvasCtx, waveformCanvasCtx;

        // Data arrays to hold audio analysis data
        let frequencyDataArray; // Stores frequency spectrum data (Uint8Array)
        let waveformTimeDomainDataArray; // Stores time domain (waveform) data (Uint8Array)

        // Animation frame ID for the main animation loop
        let animationFrameId;

        // Get references to various DOM elements
        const audioFileInput = document.getElementById('audioFile');
        const fileNameDisplay = document.getElementById('fileNameDisplay');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const fileDetailsContainer = document.getElementById('file-details');
        const audioControls = document.getElementById('audioControls');
        const playButton = document.getElementById('playButton');
        const pauseButton = document.getElementById('pauseButton');
        const frequencyTitle = document.getElementById('frequencyTitle');
        const waveformTitle = document.getElementById('waveformTitle');

        // New elements for enhanced features
        const realtimeMetrics = document.getElementById('realtimeMetrics');
        const currentDominantFrequency = document.getElementById('currentDominantFrequency');
        const currentPeakAmplitude = document.getElementById('currentPeakAmplitude');
        const volumeSlider = document.getElementById('volumeSlider');
        const audioProgressBar = document.getElementById('audioProgressBar');
        const currentTimeDisplay = document.getElementById('currentTimeDisplay');
        const durationDisplay = document.getElementById('durationDisplay');

        // References for the custom message box
        const messageBox = document.getElementById('messageBox');
        const messageBoxText = document.getElementById('messageBoxText');
        const messageBoxClose = document.getElementById('messageBoxClose');

        /**
         * Displays a custom modal message box.
         * This replaces the browser's default alert() for a consistent UI.
         * @param {string} message - The message text to be displayed.
         */
        function showMessageBox(message) {
            messageBoxText.textContent = message;
            messageBox.classList.remove('hidden'); // Show the message box
        }

        // Event listener to close the custom message box
        messageBoxClose.addEventListener('click', () => {
            messageBox.classList.add('hidden'); // Hide the message box
        });

        /**
         * Initializes the Web Audio API context and analyser node.
         * Resumes the audio context if it's in a 'suspended' state, which is common
         * due to browser autoplay policies requiring user interaction.
         */
        function initializeAudioContext() {
            // Create a new AudioContext if it doesn't exist
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            // Attempt to resume the audio context. This is crucial for playback
            // on browsers that suspend audio contexts until a user gesture.
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }
            // Create an AnalyserNode if it doesn't exist
            if (!analyser) {
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048; // Sets the window size for FFT, affecting detail.
                                        // A common value for good balance.
            }
            // Initialize or re-initialize data arrays based on the analyser's settings
            frequencyDataArray = new Uint8Array(analyser.frequencyBinCount);
            waveformTimeDomainDataArray = new Uint8Array(analyser.fftSize);
        }

        /**
         * Clears all content from canvases and resets all displayed metrics.
         */
        function clearCanvasesAndMetrics() {
            if (frequencyCanvasCtx) {
                frequencyCanvasCtx.clearRect(0, 0, frequencyCanvas.width, frequencyCanvas.height);
            }
            if (waveformCanvasCtx) {
                waveformCanvasCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
            }
            currentDominantFrequency.textContent = '0.00'; // Reset dominant frequency display
            currentPeakAmplitude.textContent = '0.00'; // Reset peak amplitude display
            currentTimeDisplay.textContent = '00:00'; // Reset current time
            durationDisplay.textContent = '00:00'; // Reset duration
            audioProgressBar.value = 0; // Reset progress bar
        }

        /**
         * Converts seconds into a formatted MM:SS string.
         * @param {number} seconds - The time in seconds.
         * @returns {string} - Formatted time string (e.g., "01:30").
         */
        function formatTime(seconds) {
            const minutes = Math.floor(seconds / 60);
            const remainingSeconds = Math.floor(seconds % 60);
            return `${String(minutes).padStart(2, '0')}:${String(remainingSeconds).padStart(2, '0')}`;
        }

        /**
         * Handles the selection of an audio file by the user.
         * Reads the file, decodes its audio data to extract metadata,
         * prepares the HTML audio element, and sets up the analyser for visualization.
         * @param {Event} event - The 'change' event from the file input.
         */
        async function handleFileSelect(event) {
            const file = event.target.files[0];
            if (!file) {
                // If no file is selected, reset the UI
                fileNameDisplay.textContent = "No file selected";
                fileDetailsContainer.classList.add('hidden');
                audioControls.classList.add('hidden');
                realtimeMetrics.classList.add('hidden'); // Hide realtime metrics
                frequencyTitle.classList.add('hidden');
                waveformTitle.classList.add('hidden');
                clearCanvasesAndMetrics();
                return;
            }

            // Update UI to show selected file name and display loading state
            fileNameDisplay.textContent = `Selected: ${file.name}`;
            fileDetailsContainer.classList.add('hidden');
            audioControls.classList.add('hidden');
            realtimeMetrics.classList.add('hidden'); // Hide realtime metrics
            frequencyTitle.classList.add('hidden');
            waveformTitle.classList.add('hidden');
            loadingIndicator.style.display = 'block'; // Show loading spinner
            clearCanvasesAndMetrics(); // Clear any previous visualizations and metrics

            initializeAudioContext(); // Ensure audio context and analyser are ready

            // Create or reuse the HTML audio element
            if (!audioElement) {
                audioElement = new Audio();
                audioElement.crossOrigin = 'anonymous'; // Important for Web Audio API to work with external sources

                // Event listener for when audio metadata is loaded
                audioElement.addEventListener('loadedmetadata', () => {
                    durationDisplay.textContent = formatTime(audioElement.duration);
                    audioProgressBar.max = audioElement.duration;
                });

                // Event listener for audio time updates (for progress bar)
                audioElement.addEventListener('timeupdate', () => {
                    currentTimeDisplay.textContent = formatTime(audioElement.currentTime);
                    audioProgressBar.value = audioElement.currentTime;
                });

                // Add event listeners for audio playback state changes
                audioElement.addEventListener('ended', () => {
                    pauseAudio(); // Automatically pause visualizations when audio finishes
                    showMessageBox("Audio playback finished.");
                    // Reload the page after 3 seconds
                    setTimeout(() => {
                        window.location.reload();
                    }, 3000);
                });
                audioElement.addEventListener('pause', () => {
                    cancelAnimationFrame(animationFrameId); // Cancel the main animation loop
                });
                audioElement.addEventListener('play', () => {
                    animate(); // Start the main animation loop
                });
            }

            // Connect the HTML audio element to the analyser node
            // Disconnect existing source if any to prevent multiple connections
            if (sourceNode) {
                sourceNode.disconnect();
            }
            sourceNode = audioContext.createMediaElementSource(audioElement);
            sourceNode.connect(analyser); // Connect to the analyser
            analyser.connect(audioContext.destination); // Connect analyser to speakers/output

            const reader = new FileReader();
            reader.readAsArrayBuffer(file); // Read the file content as an ArrayBuffer

            // Once the file is read, decode its audio data
            reader.onload = async () => {
                try {
                    // Decode the ArrayBuffer into an AudioBuffer.
                    // This allows access to detailed audio properties like sample rate and channel count.
                    audioBuffer = await audioContext.decodeAudioData(reader.result);

                    // Set the HTML audio element's source to the object URL of the file.
                    // This allows the browser to play the audio.
                    audioElement.src = URL.createObjectURL(file);
                    audioElement.load(); // Load the audio file into the HTML audio element

                    // Update the file details section with extracted metadata
                    fileDetailsContainer.innerHTML = `
                        <h2 class="text-2xl font-semibold text-gray-700 mb-4 border-b-2 border-blue-400 pb-2">File Details</h2>
                        <div class="detail-item"><strong>File Name:</strong> ${file.name}</div>
                        <div class="detail-item"><strong>File Size:</strong> ${(file.size / (1024 * 1024)).toFixed(2)} MB</div>
                        <div class="detail-item"><strong>File Type:</strong> ${file.type}</div>
                        <div class="detail-item"><strong>Duration:</strong> ${audioBuffer.duration.toFixed(2)} seconds</div>
                        <div class="detail-item"><strong>Sample Rate:</strong> ${audioBuffer.sampleRate / 1000} kHz</div>
                        <div class="detail-item"><strong>Channels:</strong> ${audioBuffer.numberOfChannels}</div>
                    `;
                    fileDetailsContainer.classList.remove('hidden'); // Show file details
                    audioControls.classList.remove('hidden'); // Show play/pause controls
                    realtimeMetrics.classList.remove('hidden'); // Show realtime metrics
                    frequencyTitle.classList.remove('hidden'); // Show frequency title
                    waveformTitle.classList.remove('hidden'); // Show waveform title

                    // Set initial volume slider value
                    volumeSlider.value = audioElement.volume;

                } catch (error) {
                    console.error("Error decoding audio data:", error);
                    showMessageBox("Failed to decode audio data. Please try another file. Error: " + error.message);
                    // Hide all sections if an error occurs
                    fileDetailsContainer.classList.add('hidden');
                    audioControls.classList.add('hidden');
                    realtimeMetrics.classList.add('hidden');
                    frequencyTitle.classList.add('hidden');
                    waveformTitle.classList.add('hidden');
                    clearCanvasesAndMetrics();
                } finally {
                    loadingIndicator.style.display = 'none'; // Always hide loading spinner
                }
            };

            // Handle errors during file reading
            reader.onerror = () => {
                loadingIndicator.style.display = 'none';
                showMessageBox("Error reading file. Please try again.");
                fileDetailsContainer.classList.add('hidden');
                audioControls.classList.add('hidden');
                realtimeMetrics.classList.add('hidden');
                frequencyTitle.classList.add('hidden');
                waveformTitle.classList.add('hidden');
                clearCanvasesAndMetrics();
            };
        }

        /**
         * Starts audio playback and initiates the main animation loop.
         */
        function playAudio() {
            // Check if an audio file has been loaded
            if (!audioElement || !audioElement.src) {
                showMessageBox("Please select an audio file first.");
                return;
            }
            // Resume the audio context if it's suspended
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }
            // Attempt to play the audio. Catch potential errors, especially autoplay policy issues.
            audioElement.play().catch(e => {
                showMessageBox(`Error playing audio: ${e.message}. User interaction might be required to enable autoplay.`);
                console.error("Audio playback error:", e);
            });
            // The 'play' event listener on `audioElement` will call `animate()`.
        }

        /**
         * Pauses audio playback and stops the main animation loop.
         */
        function pauseAudio() {
            if (audioElement) {
                audioElement.pause();
            }
            // The 'pause' event listener on `audioElement` will cancel `animationFrameId`.
        }

        /**
         * Adjusts the audio volume based on the slider value.
         */
        function handleVolumeChange() {
            if (audioElement) {
                audioElement.volume = parseFloat(volumeSlider.value);
            }
        }

        /**
         * Seeks the audio to a new position based on the progress bar value.
         */
        function handleProgressBarSeek() {
            if (audioElement) {
                audioElement.currentTime = parseFloat(audioProgressBar.value);
            }
        }

        /**
         * Draws the frequency spectrum visualization on the frequency canvas.
         * @param {Uint8Array} dataArray - The frequency data array.
         */
        function drawFrequencySpectrum(dataArray) {
            frequencyCanvasCtx.clearRect(0, 0, frequencyCanvas.width, frequencyCanvas.height);

            const bufferLength = dataArray.length;
            const barWidth = (frequencyCanvas.width / bufferLength) * 2.5;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                let barHeight = dataArray[i];

                const gradient = frequencyCanvasCtx.createLinearGradient(0, frequencyCanvas.height, 0, 0);
                gradient.addColorStop(0, `rgb(${barHeight + 100}, 50, 50)`);
                gradient.addColorStop(1, `rgb(${barHeight}, ${255 - barHeight}, 150)`);

                frequencyCanvasCtx.fillStyle = gradient;
                frequencyCanvasCtx.fillRect(x, frequencyCanvas.height - barHeight * 1.5, barWidth, barHeight * 1.5);

                x += barWidth + 1;
            }
        }

        /**
         * Draws the waveform visualization on the waveform canvas.
         * @param {Uint8Array} dataArray - The time domain data array.
         */
        function drawWaveformVisualization(dataArray) {
            waveformCanvasCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);

            waveformCanvasCtx.lineWidth = 2;
            waveformCanvasCtx.strokeStyle = 'rgb(75, 192, 192)';
            waveformCanvasCtx.beginPath();

            const sliceWidth = waveformCanvas.width * 1.0 / dataArray.length;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * waveformCanvas.height / 2;

                if (i === 0) {
                    waveformCanvasCtx.moveTo(x, y);
                } else {
                    waveformCanvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            waveformCanvasCtx.lineTo(waveformCanvas.width, waveformCanvas.height / 2);
            waveformCanvasCtx.stroke();
        }

        /**
         * Updates real-time audio metrics like dominant frequency and peak amplitude.
         * @param {Uint8Array} frequencyData - The frequency data array.
         * @param {Uint8Array} timeDomainData - The time domain data array.
         */
        function updateRealtimeMetrics(frequencyData, timeDomainData) {
            // Calculate Dominant Frequency
            let maxAmplitude = 0;
            let dominantFrequencyIndex = 0;
            for (let i = 0; i < frequencyData.length; i++) {
                if (frequencyData[i] > maxAmplitude) {
                    maxAmplitude = frequencyData[i];
                    dominantFrequencyIndex = i;
                }
            }

            if (audioContext.sampleRate && analyser.fftSize) {
                const dominantFreqHz = (dominantFrequencyIndex * audioContext.sampleRate) / analyser.fftSize;
                currentDominantFrequency.textContent = dominantFreqHz.toFixed(2);
            }

            // Calculate Peak Amplitude (from time domain data)
            let peak = 0;
            for (let i = 0; i < timeDomainData.length; i++) {
                // Normalize data from 0-255 to -1 to 1, then take absolute value for peak
                const value = Math.abs((timeDomainData[i] / 128.0) - 1); // 0-255 -> 0-2 -> -1 to 1, abs value
                if (value > peak) {
                    peak = value;
                }
            }
            currentPeakAmplitude.textContent = peak.toFixed(2); // Display peak as 0-1
        }

        /**
         * The main animation loop that continuously fetches audio data
         * and updates visualizations and metrics.
         */
        function animate() {
            // Get frequency and time domain data
            analyser.getByteFrequencyData(frequencyDataArray);
            analyser.getByteTimeDomainData(waveformTimeDomainDataArray);

            // Draw visualizations
            drawFrequencySpectrum(frequencyDataArray);
            drawWaveformVisualization(waveformTimeDomainDataArray);

            // Update real-time metrics
            updateRealtimeMetrics(frequencyDataArray, waveformTimeDomainDataArray);

            // Request the next animation frame only if audio is playing
            if (!audioElement.paused) {
                animationFrameId = requestAnimationFrame(animate);
            }
        }

        // --- Document Ready / Initial Setup ---
        // This block runs when the entire HTML document has been loaded and parsed.
        document.addEventListener('DOMContentLoaded', () => {
            // Get references to canvas elements and their 2D rendering contexts
            frequencyCanvas = document.getElementById('frequencyCanvas');
            waveformCanvas = document.getElementById('waveformCanvas');
            frequencyCanvasCtx = frequencyCanvas.getContext('2d');
            waveformCanvasCtx = waveformCanvas.getContext('2d');

            /**
             * Sets the dimensions of the canvases to be responsive to their container.
             * This function is called on initial load and whenever the window is resized.
             */
            const setCanvasDimensions = () => {
                // Get the current width of the parent container
                const containerWidth = frequencyCanvas.parentElement.offsetWidth;
                // Set both canvases to match the container's width
                frequencyCanvas.width = containerWidth;
                frequencyCanvas.height = 200; // Fixed height for frequency visualization
                waveformCanvas.width = containerWidth;
                waveformCanvas.height = 150; // Fixed height for waveform visualization

                // If audio is playing, immediately redraw to fit the new dimensions
                if (audioElement && !audioElement.paused) {
                    // No need to clear here as `animate` loop will redraw
                } else {
                    clearCanvasesAndMetrics(); // Clear canvas content and metrics after resizing if not playing
                }
            };

            // Set canvas dimensions initially when the page loads
            setCanvasDimensions();
            // Add an event listener to re-adjust canvas dimensions on window resize
            window.addEventListener('resize', setCanvasDimensions);

            // Attach event listeners to the file input and playback control buttons
            audioFileInput.addEventListener('change', handleFileSelect);
            playButton.addEventListener('click', playAudio);
            pauseButton.addEventListener('click', pauseAudio);
            volumeSlider.addEventListener('input', handleVolumeChange); // Volume slider listener
            audioProgressBar.addEventListener('input', handleProgressBarSeek); // Progress bar seek listener
        });
    </script>
</body>
</html>
